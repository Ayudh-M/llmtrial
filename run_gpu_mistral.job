#!/bin/bash
#SBATCH -J consensus_mistral
#SBATCH -A tesr108469
#SBATCH -p gpu_h100
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=40G
#SBATCH --time=00:30:00
#SBATCH -o logs/%x-%j.out

set -euo pipefail
cd "$SLURM_SUBMIT_DIR"
mkdir -p logs runs analytics

# Fresh cache per job on node-local scratch
export HF_HOME="${TMPDIR:-/scratch-local/$USER/${SLURM_JOB_ID}}/hf"
mkdir -p "$HF_HOME"

export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export PYTHONPATH="$SLURM_SUBMIT_DIR/src:${PYTHONPATH:-}"

source ~/.venvs/consensus/bin/activate

SCENARIO_ID="${1:?usage: sbatch run_gpu_mistral.job <scenario_id>}"

# Force exact model ids (overrides registry if needed)
srun --ntasks=1 python -m src.main --scenario "$SCENARIO_ID" \
  --model-a mistralai/Mistral-7B-Instruct-v0.3 \
  --model-b mistralai/Mistral-7B-Instruct-v0.3 \
  --dtype bf16
